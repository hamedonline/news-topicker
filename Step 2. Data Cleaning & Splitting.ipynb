{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Splitting\n",
    "\n",
    "During this step we'll be doing some clean-up based on the insights we acquired through __EDA__. We are going to split data into two representative parts (train & test) as well, since a separate test dataset is not provided; eventually we'll save the cleaned data files separately to facilitate a hassle-free loading for the next phase (model training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required library imports & initial settings\n",
    "\n",
    "import re\n",
    "import string\n",
    "import wordninja\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "RANDOM_SEED = 1024\n",
    "test_size_fraction = 0.2\n",
    "column_target = 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200848</th>\n",
       "      <td>TECH</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Reuters, Reuters</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/rim-ceo-t...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/maria-sha...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/super-bow...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/aldon-smi...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/dwight-ho...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200853 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                           headline  \\\n",
       "0               CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1       ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2       ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3       ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4       ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "...               ...                                                ...   \n",
       "200848           TECH  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "200849         SPORTS  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "200850         SPORTS  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "200851         SPORTS  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "200852         SPORTS  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                 authors                                               link  \\\n",
       "0        Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1          Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2             Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3             Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4             Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "...                  ...                                                ...   \n",
       "200848  Reuters, Reuters  https://www.huffingtonpost.com/entry/rim-ceo-t...   \n",
       "200849               NaN  https://www.huffingtonpost.com/entry/maria-sha...   \n",
       "200850               NaN  https://www.huffingtonpost.com/entry/super-bow...   \n",
       "200851               NaN  https://www.huffingtonpost.com/entry/aldon-smi...   \n",
       "200852               NaN  https://www.huffingtonpost.com/entry/dwight-ho...   \n",
       "\n",
       "                                        short_description        date  \n",
       "0       She left her husband. He killed their children...  2018-05-26  \n",
       "1                                Of course it has a song.  2018-05-26  \n",
       "2       The actor and his longtime girlfriend Anna Ebe...  2018-05-26  \n",
       "3       The actor gives Dems an ass-kicking for not fi...  2018-05-26  \n",
       "4       The \"Dietland\" actress said using the bags is ...  2018-05-26  \n",
       "...                                                   ...         ...  \n",
       "200848  Verizon Wireless and AT&T are already promotin...  2012-01-28  \n",
       "200849  Afterward, Azarenka, more effusive with the pr...  2012-01-28  \n",
       "200850  Leading up to Super Bowl XLVI, the most talked...  2012-01-28  \n",
       "200851  CORRECTION: An earlier version of this story i...  2012-01-28  \n",
       "200852  The five-time all-star center tore into his te...  2012-01-28  \n",
       "\n",
       "[200853 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define relative data path (according the current path of this notebook) and data file name\n",
    "DATA_PATH = './scripts/data'\n",
    "FILE_NAME = 'dataset_all.csv.gz'\n",
    "\n",
    "df_all = pd.read_csv(f'{DATA_PATH}/{FILE_NAME}')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples with missing values in 'headline' column\n",
    "df_all = df_all.dropna(subset=['headline']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Inconsistencies of Target Column Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a category tranformer function based on lexical similarity scores and the intuition we have after EDA\n",
    "def transform_category(value):\n",
    "    if value in ['ARTS', 'CULTURE & ARTS']:\n",
    "        return 'ARTS & CULTURE'\n",
    "    elif value in ['THE WORLDPOST', 'WORLDPOST']:\n",
    "        return 'WORLD NEWS'\n",
    "    elif value in ['STYLE']:\n",
    "        return 'STYLE & BEAUTY'\n",
    "    elif value in ['PARENTS']:\n",
    "        return 'PARENTING'\n",
    "    elif value in ['TASTE']:\n",
    "        return 'FOOD & DRINK'\n",
    "    elif value in ['GREEN', 'ENVIRONMENT']:\n",
    "        return 'GREEN & ENVIRONMENT'\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "df_all[column_target] = df_all.apply(lambda row: transform_category(row[column_target]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200842</th>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>TECH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200843</th>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200844</th>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200845</th>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200846</th>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200847 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline       category\n",
       "0       There Were 2 Mass Shootings In Texas Last Week...          CRIME\n",
       "1       Will Smith Joins Diplo And Nicky Jam For The 2...  ENTERTAINMENT\n",
       "2         Hugh Grant Marries For The First Time At Age 57  ENTERTAINMENT\n",
       "3       Jim Carrey Blasts 'Castrato' Adam Schiff And D...  ENTERTAINMENT\n",
       "4       Julianna Margulies Uses Donald Trump Poop Bags...  ENTERTAINMENT\n",
       "...                                                   ...            ...\n",
       "200842  RIM CEO Thorsten Heins' 'Significant' Plans Fo...           TECH\n",
       "200843  Maria Sharapova Stunned By Victoria Azarenka I...         SPORTS\n",
       "200844  Giants Over Patriots, Jets Over Colts Among  M...         SPORTS\n",
       "200845  Aldon Smith Arrested: 49ers Linebacker Busted ...         SPORTS\n",
       "200846  Dwight Howard Rips Teammates After Magic Loss ...         SPORTS\n",
       "\n",
       "[200847 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_desired = ['headline', 'category']\n",
    "\n",
    "df_all = df_all[columns_desired]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Representative Train & Test Sets\n",
    "This should take place before going any further; because we will be doing some additional data cleaning which should only be done on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's shuffle the whole dataframe before proceeding\n",
    "df_all = df_all.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "# second shuffle with an exponential random seed :D\n",
    "df_all = df_all.sample(frac=1, random_state=(RANDOM_SEED**2)).reset_index(drop=True)\n",
    "\n",
    "# split the data into representative training and test sets\n",
    "df_train, df_test = train_test_split(df_all, test_size=test_size_fraction, stratify=df_all[column_target], random_state=RANDOM_SEED)\n",
    "\n",
    "# reset the index of the dataframes\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ You may have heard many times that for final training, we should use the entire dataset. As a side note, we'll be applying all train set considerations to this separate entire set as well; so that we can have an entire dataset ready to use for the final training. No test set exists in this scenario, and the test cases would be unseen out of sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Train Data\n",
    "We need to do some preprocessing on the training data, which will help us further clean the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_preprocessed</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medicare Supplemental Policies: Do You Need One?</td>\n",
       "      <td>medicare supplemental policies do you need one</td>\n",
       "      <td>WELLNESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 Tips For You And Your Dog This July 4th</td>\n",
       "      <td>7 tips for you and your dog this july 4th</td>\n",
       "      <td>GREEN &amp; ENVIRONMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Best Hotel-Hosted Super Bowl Parties In La...</td>\n",
       "      <td>the best hotelhosted super bowl parties in las...</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even If You Lose The Weight, Obesity May Still...</td>\n",
       "      <td>even if you lose the weight obesity may still ...</td>\n",
       "      <td>HEALTHY LIVING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cocaine Cowboy 'White Boy Rick' Could Be Relea...</td>\n",
       "      <td>cocaine cowboy white boy rick could be release...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0   Medicare Supplemental Policies: Do You Need One?   \n",
       "1          7 Tips For You And Your Dog This July 4th   \n",
       "2  The Best Hotel-Hosted Super Bowl Parties In La...   \n",
       "3  Even If You Lose The Weight, Obesity May Still...   \n",
       "4  Cocaine Cowboy 'White Boy Rick' Could Be Relea...   \n",
       "\n",
       "                               headline_preprocessed             category  \n",
       "0     medicare supplemental policies do you need one             WELLNESS  \n",
       "1          7 tips for you and your dog this july 4th  GREEN & ENVIRONMENT  \n",
       "2  the best hotelhosted super bowl parties in las...               TRAVEL  \n",
       "3  even if you lose the weight obesity may still ...       HEALTHY LIVING  \n",
       "4  cocaine cowboy white boy rick could be release...                CRIME  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    '''\n",
    "    Applies text preprocessing to input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): example => 'This, is the #TEXT   that needs   to be preprocessed.  '\n",
    "\n",
    "    Returns:\n",
    "        str: example => 'this is the text that needs to be preprocessed'\n",
    "    '''\n",
    "    text = text.lower()  # convert to lowercase\n",
    "    text = re.sub('(#)(\\S+)', r' \\2', text)  # remove hashtags sign\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  # remove punctuations\n",
    "    text = re.sub(' +', ' ', text)  # replace multiple whitespaces with a single space\n",
    "    text = text.strip()  # remove leading and trailing whitespaces\n",
    "    return text\n",
    "\n",
    "\n",
    "# create a new column in train dataframe which contains headline in preprocessed form\n",
    "df_train['headline_preprocessed'] = df_train.apply(lambda row: preprocess_text(str(row['headline'])), axis=1)\n",
    "# do the same for our separate 'entire' train dataframe\n",
    "df_all['headline_preprocessed'] = df_all.apply(lambda row: preprocess_text(str(row['headline'])), axis=1)\n",
    "\n",
    "# re-order columns\n",
    "columns_order = ['headline', 'headline_preprocessed', 'category']\n",
    "df_train = df_train[columns_order]\n",
    "df_all = df_all[columns_order]\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Further Data Cleaning on Train Data\n",
    "This is where we check character length and word count of the headlines and remove any rows that do not meet the requirements we identified during the __EDA__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_concatenated(text: str) -> str:\n",
    "    '''\n",
    "    splits words of a concatenated English text string.\n",
    "\n",
    "    Args:\n",
    "        text (str): example => 'thistextstringisconcatenated'\n",
    "\n",
    "    Returns:\n",
    "        str: example => 'this text string is concatenated'\n",
    "    '''\n",
    "    text = ' '.join(wordninja.split(text))\n",
    "    return text\n",
    "\n",
    "\n",
    "# apply splitting function to headlines with just 1 word\n",
    "df_train['headline_preprocessed'] = df_train['headline_preprocessed'].map(lambda value: split_concatenated(value) if (len(str(value).split()) < 2) else value)\n",
    "# apply the same process to our separate 'entire' train dataframe\n",
    "df_all['headline_preprocessed'] = df_all['headline_preprocessed'].map(lambda value: split_concatenated(value) if (len(str(value).split()) < 2) else value)\n",
    "\n",
    "# drop remaining rows with only 1 word in headline\n",
    "df_train = df_train.loc[~df_train['headline_preprocessed'].str.split().str.len() < 2].reset_index(drop=True)\n",
    "# the same for our separate 'entire' train dataframe\n",
    "df_all = df_all.loc[~df_all['headline_preprocessed'].str.split().str.len() < 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop samples having headlines with character length <= 10 and words count above 2\n",
    "df_train = df_train.loc[~(df_train['headline_preprocessed'].str.len() <= 10) & (df_train['headline_preprocessed'].str.split().str.len() > 2)].reset_index(drop=True)\n",
    "# the same for our separate 'entire' train dataframe\n",
    "df_all = df_all.loc[~(df_all['headline_preprocessed'].str.len() <= 10) & (df_all['headline_preprocessed'].str.split().str.len() > 2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Cleaned Versions of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(f'{DATA_PATH}/train_cleaned.csv.gz', compression='gzip', index=False)\n",
    "df_test.to_csv(f'{DATA_PATH}/test_cleaned.csv.gz', compression='gzip', index=False)\n",
    "df_all.to_csv(f'{DATA_PATH}/train_cleaned_entire.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
